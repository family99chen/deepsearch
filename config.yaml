# ORCID API 配置
orcid:
  access_token: "ffc8fc1b-accd-4002-9317-5c0cabdc8e77"
  api_base_url: "https://pub.orcid.org/v3.0"

# Google Scholar 配置
google_scholar:
  search_base_url: "https://scholar.google.com"

# Google Custom Search API 配置
google:
  api_key: "AIzaSyAx7Gy4iSDzyHxbA7iTaG4pIwoK0Ff8kj8"
  cx: "d75a80598807a44f4"
  # API 限制：免费版每天 100 次查询
  # 付费版：$5/1000 次查询
  rate_limit: 1000  # 每秒最大请求数

# SerpAPI 配置 (Google Scholar 搜索)
serpapi:
  api_key: "2b7f0241c4106975462e8a8159cb7a3cd5ca0d48657547a678f00fc4b0d17551"
  # API 限制：免费版每月 100 次
  # 付费版：$50/5000 次
  max_retries: 3
  timeout: 30

# Pipeline 配置
pipeline:
  # 搜索候选人迭代次数（每次搜索 10 条）
  # 迭代次数 × 10 = 最大搜索候选人数
  # 例如：max_iterations=5 表示最多搜索 50 个候选人
  max_iterations: 1
  # 论文标题匹配阈值 (0-1)
  match_threshold: 0.9
  # 每个候选人最大匹配论文数
  max_matches: 150

# 代理配置
proxy:
  enabled: false
  url: ""

# MongoDB 缓存配置（使用独立的无认证实例）
mongodb:
  host: "localhost"
  port: 27018  # 独立 MongoDB 实例
  db_name: "deepsearch_cache"
  collection: "api_cache"
  # 无需认证
  # username: ""
  # password: ""

# LLM 配置
llm:
  # 后端选择: "api" | "local" | "auto"
  # - api: 使用云端 API（OpenAI、Claude 等）
  # - local: 使用本地部署的模型
  # - auto: 自动选择（优先本地，本地不可用时使用 API）
  backend: "api"
  
  # 云端 API 配置（OpenAI 兼容格式）
  api:
    api_key: "sk-zk200fee8578937a24d5206025c1500aaa368ff3f37ca32c"  # 填入你的 API Key
    api_base: "https://api.zhizengzeng.com/v1"  # 或其他兼容的 API
    model: "gpt-4o-mini"
    timeout: 120  # 超时时间（秒）
  
  # 本地模型配置（OpenAI 兼容格式）
  local:
    api_base: "http://localhost:11434/v1"  # Ollama 默认地址
    model: "qwen2.5:7b"  # 本地模型名称
    timeout: 300  # 本地模型可能需要更长时间

# Iter Agent 配置（迭代式网页深挖）
iter_agent:
  # 最大迭代次数 (k)
  # 每次迭代会读取上一轮发现的所有链接
  # 例如：k=3 表示最多进行 3 轮深挖
  max_iterations: 3
  
  # 每个页面最多返回的链接数 (n)
  # 每个页面分析后最多返回 n 个可能包含目标人物信息的链接
  # 注意：第 i 轮如果有 m 个页面，下一轮最多会有 m*n 个链接
  max_links_per_page: 3

# Iteragent Advanced 配置（智能浏览代理）
iteragent_advanced:
  # 最大迭代次数
  # 每次迭代 Brain 会决定一个动作（点击、搜索、返回等）
  max_iterations: 6
  
  # 提示词中显示的历史记录条数
  max_history_in_prompt: 5

# Organization Pipeline 配置（组织人员信息收集管道）
organization_pipeline:
  # 最大处理链接数
  # 从 Google Search 获取的链接中，最多处理多少个
  max_links: 10
  
  # 最大并发数
  # 同时处理多少个链接
  max_concurrent: 3
  
  # 注意：iter_agent 和 brain 的迭代次数使用各自模块的配置
  # - iter_agent.max_iterations
  # - iteragent_advanced.max_iterations

# Person Pipeline 配置（总 Pipeline）
person_pipeline:
  # LLM 后端选择: "api" | "local" | "auto"
  backend: "api"
  # LLM 模型名称（仅在 api/local 对应后端时生效）
  model: "gpt-5.2"
  # 最大迭代次数
  max_iterations: 1
  # 最大处理链接数
  max_links: 10
  # 最大并发数
  max_workers: 3

